{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulinaWalasiewicz/Colab-notebooks/blob/main/Copy_of_NN_model_training_with_tabular_data_Vistula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import niezbednych bibliotek\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "Z2oVN4obSup7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Przygotowanie przykładowych danych\n",
        "data = {\n",
        "    'Category': ['Electronics', 'Furniture', 'Clothing', 'Electronics', 'Clothing'],\n",
        "    'Region': ['North', 'South', 'East', 'West', 'North'],\n",
        "    'Sales': [200, 300, 150, 400, 250],\n",
        "    'Time on Platform': [30, 45, 20, 50, 35],\n",
        "    'Target': [1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "# Konwersja danych do pandas DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "EAJWdXsHS-J4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja do kodowania wartości kategorycznych\n",
        "def encode_categorical_columns(df, columns):\n",
        "    label_encoders = {}\n",
        "    for col in columns:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "    return label_encoders\n",
        "\n",
        "# Funkcja do standaryzacji wartości numerycznych\n",
        "def standardize_columns(df, columns):\n",
        "    scaler = StandardScaler()\n",
        "    df[columns] = scaler.fit_transform(df[columns])\n",
        "    return scaler\n",
        "\n",
        "# Kodowanie kolumn kategorycznych\n",
        "categorical_columns = ['Category', 'Region']\n",
        "label_encoders = encode_categorical_columns(df, categorical_columns)\n",
        "\n",
        "# Standaryzacja kolumn numerycznych\n",
        "numerical_columns = ['Sales', 'Time on Platform']\n",
        "scaler = standardize_columns(df, numerical_columns)\n",
        "\n",
        "# Podział danych na zbiory treningowy i testowy\n",
        "features = ['Category', 'Region', 'Sales', 'Time on Platform']\n",
        "X = df[features]\n",
        "y = df['Target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mgXF4ryzTK6Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicja modelu embeddingów\n",
        "class EmbeddingModel(nn.Module):\n",
        "    def __init__(self, embedding_sizes, num_numerical_features):\n",
        "        \"\"\"\n",
        "        Inicjalizacja modelu.\n",
        "        embedding_sizes: lista krotek (liczba kategorii, rozmiar embeddingow) dla zmiennych kategorycznych.\n",
        "        num_numerical_features: liczba cech numerycznych.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Tworzenie listy warstw embeddingow dla zmiennych kategorycznych\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(num_embeddings=categories, embedding_dim=size)\n",
        "            for categories, size in embedding_sizes\n",
        "        ])\n",
        "\n",
        "        # Warstwy w pełni połączone (fully connected)\n",
        "        input_size = sum([size for _, size in embedding_sizes]) + num_numerical_features\n",
        "        self.fc1 = nn.Linear(input_size, 32)  # Pierwsza warstwa w pełni połączona\n",
        "        self.fc2 = nn.Linear(32, 16)         # Druga warstwa w pełni połączona\n",
        "        self.output = nn.Linear(16, 1)      # Warstwa wyjściowa\n",
        "        self.dropout = nn.Dropout(0.2)      # Dropout dla regularyzacji\n",
        "\n",
        "    def forward(self, x_categorical, x_numerical):\n",
        "        \"\"\"\n",
        "        Propagacja w przód (forward pass).\n",
        "        x_categorical: tensor wejściowy dla zmiennych kategorycznych.\n",
        "        x_numerical: tensor wejściowy dla cech numerycznych.\n",
        "        \"\"\"\n",
        "        # Embeddingi dla zmiennych kategorycznych\n",
        "        embedded = [emb(x_categorical[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        embedded = torch.cat(embedded, dim=1)  # Konkatenacja embeddingow\n",
        "\n",
        "        # Połączenie embeddingow ze zmiennymi numerycznymi\n",
        "        x = torch.cat([embedded, x_numerical], dim=1)\n",
        "\n",
        "        # Przepływ przez warstwy w pełni połączone z funkcją aktywacji ReLU\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(torch.relu(self.fc2(x)))\n",
        "\n",
        "        # Warstwa wyjściowa z funkcją aktywacji sigmoid\n",
        "        return torch.sigmoid(self.output(x))"
      ],
      "metadata": {
        "id": "i5DF4HgGTdld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZTm6-i3gQ4sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7055a7dc-cf83-49dd-8bc9-1f89fe0d4024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmbeddingModel(\n",
            "  (embeddings): ModuleList(\n",
            "    (0): Embedding(3, 4)\n",
            "    (1): Embedding(4, 4)\n",
            "  )\n",
            "  (fc1): Linear(in_features=10, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (output): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Określenie rozmiarów wektorów embeddingów dla zmiennych kategorycznych\n",
        "# embedding_sizes: lista krotek (liczba unikalnych wartości w kolumnie, rozmiar embeddingu)\n",
        "embedding_sizes = [\n",
        "    (df['Category'].nunique(), 4),  # 'Product Category': liczba kategorii i rozmiar embeddingu\n",
        "    (df['Region'].nunique(), 4)   # 'Customer Region': liczba regionów i rozmiar embeddingu\n",
        "]\n",
        "\n",
        "# Konwersja danych na tensory\n",
        "# Dane kategoryczne (train)\n",
        "X_categorical_train = torch.tensor(\n",
        "    X_train[['Category', 'Region']].values, dtype=torch.long\n",
        ")\n",
        "\n",
        "# Dane numeryczne (train)\n",
        "X_numerical_train = torch.tensor(\n",
        "    X_train[['Sales', 'Time on Platform']].values, dtype=torch.float\n",
        ")\n",
        "\n",
        "# Target (wartości wyjściowe) jako tensor (przekształcenie na kolumnowy tensor)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "# Utworzenie instancji modelu oraz optymalizatora gradientowego\n",
        "# EmbeddingModel: model uwzględniający embeddingi i dane numeryczne\n",
        "model = EmbeddingModel(embedding_sizes, num_numerical_features=2)\n",
        "\n",
        "# Kryterium strat: funkcja Binary Cross-Entropy (BCELoss)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optymalizator: Adam z ustaloną wartością learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Pętla trenująca model\n",
        "epochs = 50  # Liczba epok\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()                  # Zerowanie gradientów\n",
        "    outputs = model(X_categorical_train, X_numerical_train)  # Przepływ danych przez model\n",
        "    loss = criterion(outputs, y_train_tensor)  # Obliczanie strat\n",
        "    loss.backward()                     # Wyznaczanie gradientów\n",
        "    optimizer.step()                    # Aktualizacja wag modelu\n",
        "\n",
        "# Wyświetlenie oceny modelu w trybie ewaluacji\n",
        "print(model.eval())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/model/trained_model.pth\"\n",
        "# path = \"/content/trained_model.pth\"\n",
        "torch.save(model, path)"
      ],
      "metadata": {
        "id": "1s0AYLp_voE9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(path)\n",
        "checkpoint.eval()"
      ],
      "metadata": {
        "id": "oql_Dzl3wEXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Przygotowanie danych do inferencji modelu\n",
        "# ZAD1. Wykonajcie inferencje i zapiszcie wynik dla 10 roznych wartosci data_inf\n",
        "data_inf = {\n",
        "    'Category': ['Electronics', 'Furniture', 'Clothing', 'Electronics', 'Clothing', 'Electronics', 'Furniture', 'Clothing', 'Electronics', 'Clothing'],\n",
        "    'Region': ['North', 'South', 'East', 'West', 'North', 'North', 'South', 'East', 'West', 'North'],\n",
        "    'Sales': [200, 300, 150, 400, 250, 200, 300, 150, 400, 250],\n",
        "    'Time on Platform': [30, 45, 20, 50, 35, 30, 45, 20, 50, 35]\n",
        "}\n",
        "\n",
        "# Konwersja do pandas DataFrame\n",
        "df_inf = pd.DataFrame(data_inf)\n",
        "\n",
        "# Kodowanie kolumn kategorycznych\n",
        "label_encoders = encode_categorical_columns(df_inf, categorical_columns)\n",
        "\n",
        "# Standaryzacja kolumn numerycznych\n",
        "scaler = standardize_columns(df_inf, numerical_columns)\n",
        "\n",
        "# Podział danych na zbiory treningowy i testowy\n",
        "features = ['Category', 'Region', 'Sales', 'Time on Platform']\n",
        "X = df_inf[features]\n",
        "\n",
        "X_categorical_inf = torch.tensor(\n",
        "    X[['Category', 'Region']].values, dtype=torch.long\n",
        ")\n",
        "\n",
        "# Dane numeryczne (train)\n",
        "X_numerical_inf = torch.tensor(\n",
        "    X[['Sales', 'Time on Platform']].values, dtype=torch.float\n",
        ")\n",
        "\n",
        "output_inf = checkpoint(X_categorical_inf, X_numerical_inf)\n",
        "\n",
        "# Wynik inferencji to tzw. logit, im blizej, 0 tym wieksza pewnosc modelu ze Target = 0, im blizej 1, wym wieksza pewnosc modelu ze target = 1. Wszystko pomiedzy 0 i 1 obarczone jest niepewnoscia modelu co do poprawnego wyniku, przy czym najwieksza niepewnosc modelu oznacza wynik inferencji - 0.5\n",
        "print(output_inf)"
      ],
      "metadata": {
        "id": "OZcbeaYkllFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list = output_inf.detach().numpy().tolist()\n",
        "\n",
        "print(output_list)  # Wyświetli listę liczb"
      ],
      "metadata": {
        "id": "cQ6svsNL8lbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list = output_inf.detach().numpy().tolist()\n",
        "\n",
        "formatted_list = []\n",
        "for sublist in output_list:\n",
        "    for number in sublist:\n",
        "        formatted_list.append(format(number, '.10f'))  # Formatowanie do 10 miejsc po przecinku\n",
        "\n",
        "print(formatted_list)  # Wyświetli listę liczb w standardowej postaci dziesiętnej"
      ],
      "metadata": {
        "id": "-Akr6KJq8lf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZAD2. Zmodyfikujcie kod tak, aby oprocz wyniku (logit) zostal rowniez zwracany embedding dla rekordu na wyjciu warstwy fc2. Wskazowka: Zmian nalezy dokonac tylko w czesci # Zdefiniowanie modelu\n",
        "# ZAD3. W definicji modelu, dodajcie kolejna, trzecia warstwe liniowa w pelni polaczona fc3, tak aby fc2 miala wymiar (32, 32) oraz fc3 miala wymiar (32,16)\n",
        "# ZAD4. Poeksperymentujcie jak wplynie na dokladnosc przewidywania modelu zmiana nastepujacych parametrow modelu i trenera:\n",
        "#   - dodanie kolejnych warstw liniowych do modelu fc4 i fc5\n",
        "#   - zmiana wymiaru wejsie-wyjscie warstw liniowych fc1, fc2, fc3, ...\n",
        "#   - zmniejszenie lub zwiększenie (max lr = 1) wartosci kroku w optymalizatorze (lr)"
      ],
      "metadata": {
        "id": "eLQUWPpXeEcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}